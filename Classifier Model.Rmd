---
title: "Classifier Model"
author: "Yu Dong"
date: "9/25/2018"
output: html_document
---


```{r load package and data}
library(tidyverse)
library(catboost)
library(caret)

load('input/new_feature2.RData')
```


Add a classifier on the top to the regression model

```{r modeling}
all_data$purchaseFlag = ifelse(all_data$transactionRevenue > 0, 1, 0)

data_train = all_data[all_data$set== 'train',-c(1,2,98,99)]
train_pool = catboost.load_pool(
    data = data_train[,-96],
    label = data_train[,96],
    cat_features = c(2,3,5:16,19,24,25,26,28,30,31))


data_test = all_data[all_data$set== 'test',-c(1,2,98,99)]
test_pool = catboost.load_pool(
    data = data_test[,-96],
    label = data_test[,96],
    cat_features = c(2,3,5:16,19,24,25,26,28,30,31))

###

fit_params <- list(loss_function = 'Logloss',
                   custom_loss = 'F1',
                   iterations = 4000,
                   learning_rate = 0.01,
                   random_seed = 42,
                   rsm = 0.95,
                   l2_leaf_reg = 3,
                   depth = 8,
                   one_hot_max_size = 100,
                   train_dir = 'train_dir',
                   verbose = 100)

model <- catboost.train(
    learn_pool = train_pool, 
    params = fit_params)

###

prediction1 <- catboost.predict(model, 
                               test_pool, 
                               prediction_type = 'RawFormulaVal')


prediction1 = ifelse(prediction1 <0, 0, ifelse(prediction1<1, prediction1, 1))

submission1 = data.frame(
    fullVisitorId = all_data[all_data$set== 'test',]$fullVisitorId, 
    bounces = all_data[all_data$set== 'test',]$bounces,
    prediction = prediction1)

submission1$prediction = ifelse(submission1$bounces == 1, 0, submission1$prediction)

submission1$bounces = NULL

submission1 = submission1 %>% 
    group_by(fullVisitorId) %>%
    summarise(prediction = ifelse(sum(prediction) < 1, sum(prediction), 1))

submission2 = read.csv('/Users/hzdy1994/Desktop/Kaggle - Customer Revenue Prediction/submission/submission092401.csv')

submission = cbind(submission1, submission2$PredictedLogRevenue)
submission$PredictedLogRevenue = submission$prediction * submission$PredictedLogRevenue

submission$prediction = NULL

submission$PredictedLogRevenue = as.character(submission$PredictedLogRevenue)

write.csv(submission, 'submission/submission092501.csv', row.names=FALSE)
# use the probability directly: LB: 1.7311

```

Use a 0.5 threshold

```{r prediction2}
prediction1 <- catboost.predict(model, 
                               test_pool, 
                               prediction_type = 'RawFormulaVal')


prediction1 = ifelse(prediction1 <0.3, 0, 1)

submission1 = data.frame(
    fullVisitorId = all_data[all_data$set== 'test',]$fullVisitorId, 
    bounces = all_data[all_data$set== 'test',]$bounces,
    prediction = prediction1)

submission1$prediction = ifelse(submission1$bounces == 1, 0, submission1$prediction)

submission1$bounces = NULL

submission1 = submission1 %>% 
    group_by(fullVisitorId) %>%
    summarise(prediction = ifelse(sum(prediction) < 1, sum(prediction), 1))

#submission2 = read.csv('/Users/hzdy1994/Desktop/Kaggle - Customer Revenue Prediction/submission/submission092401.csv')

submission = cbind(submission1, PredictedLogRevenue = submission2$PredictedLogRevenue)
submission$PredictedLogRevenue = submission$prediction * submission$PredictedLogRevenue

submission$prediction = NULL

submission$PredictedLogRevenue = as.character(submission$PredictedLogRevenue)


write.csv(submission, 'submission/submission092503.csv', row.names=FALSE)
# 0.5 threshod: LB 1.7466
# 0.3 threshod: LB 1.7334
## how about using it as part of the predictor for the regressor...

```

Add Classifier result as a new feature for the regressor

```{r classfier as feature}
load('input/new_feature3.RData')

all_data$purchaseFlag = ifelse(all_data$transactionRevenue > 0, 1, 0)

data_train = all_data[all_data$set== 'train',-c(1,2,102)]
data_train = data_train %>% filter(bounces == 0)
train_pool = catboost.load_pool(
    data = data_train[,-c(100,101)],
    label = data_train[,101],
    cat_features = c(2,3,5:16,19,24,25,26,28,30,31))


data_test = all_data[all_data$set== 'test',-c(1,2,102)]
data_test = data_test %>% filter(bounces == 0)
test_pool = catboost.load_pool(
    data = data_test[,-c(100,101)],
    label = data_test[,101],
    cat_features = c(2,3,5:16,19,24,25,26,28,30,31))

### modeling

fit_params <- list(loss_function = 'Logloss',
                   custom_loss = 'F1',
                   iterations = 1000,
                   learning_rate = 0.005,
                   random_seed = 1,
                   rsm = 0.95,
                   l2_leaf_reg = 3,
                   depth = 8,
                   one_hot_max_size = 100,
                   class_weights = c(0.1, 3),
                   train_dir = 'train_dir_classifier',
                   verbose = 500)

model <- catboost.train(
        learn_pool = train_pool, 
        params = fit_params)
    
print('classifier training ends')

### prediction (get the classification score)

train_predict <- catboost.predict(model, 
                                  train_pool, 
                                  prediction_type = 'RawFormulaVal')

test_predict <- catboost.predict(model, 
                                 test_pool, 
                                 prediction_type = 'RawFormulaVal')

data_train$class_pred = train_predict
data_test$class_pred = test_predict
    
train_pool = catboost.load_pool(
    data = data_train[,-c(100,101)],
    label = data_train[,100],
    cat_features = c(2,3,5:16,19,24,25,26,28,30,31))
    
test_pool = catboost.load_pool(
    data = data_test[,-c(100,101)],
    label = data_test[,100],
    cat_features = c(2,3,5:16,19,24,25,26,28,30,31))

### train regression model
    
print('start regressor training')
    
fit_params <- list(loss_function = 'RMSE',
                   iterations = 2000,
                   learning_rate = 0.01,
                   random_seed = 42,
                   rsm = 0.9,
                   l2_leaf_reg = 3,
                   depth = 7,
                   border_count = 64,
                   one_hot_max_size = 100,
                   train_dir = paste0('train_dir_regressor'),
                   verbose = 500)

model <- catboost.train(
        learn_pool = train_pool,
        params = fit_params)

prediction <- catboost.predict(model, 
                               test_pool, 
                               prediction_type = 'RawFormulaVal')
    
print('regressor training ends')

## submission
    
prediction = ifelse(exp(prediction) - 1 <0, 0, exp(prediction) - 1)


submission = data.frame(fullVisitorId = filter(all_data, set== 'test', bounces == 0)$fullVisitorId, prediction = prediction)

submission = rbind(submission, 
                   data.frame(
                       fullVisitorId = filter(all_data, 
                              set== 'test', 
                              bounces == 1)$fullVisitorId, 
                       prediction = 0))

submission = submission %>% 
    group_by(fullVisitorId) %>%
    summarise(PredictedLogRevenue = log(sum(prediction)+1))

submission$PredictedLogRevenue = as.character(submission$PredictedLogRevenue)

write.csv(submission, 'submission/submission093002.csv', row.names=FALSE)

## CV: 1.597312486
## LB: 1.4726

## iter 1500 & 2500:
## CV: 1.5955064
## LB: 1.4732

## iter 1000 & 2000:
## LB: 1.4723

```

```{r}
feature_importance = data.frame(
    feature = names(data_train[,-c(100,101)]),
    score = catboost.get_feature_importance(model))
```

