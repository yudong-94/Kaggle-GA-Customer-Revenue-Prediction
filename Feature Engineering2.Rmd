---
title: "Feature Engineering2"
author: "Yu Dong"
date: "9/18/2018"
output: html_document
---


```{r load package and data}
library(tidyverse)
library(lubridate)
library(catboost)

load('input/cleaned_all_data.RData')
```


## Time features

```{r time}
all_data$visitStartTime = ymd_hms(all_data$visitStartTime)
all_data$month = month(all_data$visitStartTime)
all_data$season = ifelse(all_data$month %in% c(3,4,5), 'Spring',
                         ifelse(all_data$month %in% c(6,7,8), 'Summer',
                         ifelse(all_data$month %in% c(9,10,11), 'Fall',
                         'Winter')))

all_data$weekday = wday(all_data$visitStartTime, label = TRUE)
all_data$wday = ifelse(all_data$weekday %in% c('Sat', 'Sun'), 'weekend', 'weekday')

all_data$hour = hour(all_data$visitStartTime)
all_data$visitStartTime = NULL


all_data$wday = as.factor(all_data$wday)
all_data$season = as.factor(all_data$season)

```

## Group average data

```{r geo}
## continent
all_data %>%
    filter(set == 'train') %>%
    group_by(continent) %>%
    summarise(n = n(),
              avg_revenue = mean(transactionRevenue),
              avg_hits = mean(hits),
              median_hits = median(hits),
              max_hits = max(hits),
              avg_pageviews = mean(pageviews),
              median_pageviews = median(pageviews),
              max_pageviews = max(pageviews))

continent_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(continent) %>%
    summarise(
              avg_hits_continent = mean(hits),
              max_hits_continent = max(hits),
              avg_pageviews_continent = mean(pageviews),
              max_pageviews_continent = max(pageviews))

all_data = merge(all_data, continent_avg, by = 'continent', all.x=TRUE)


## sub continent

subcontinent_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(subContinent) %>%
    summarise(
              avg_hits_subcontinent = mean(hits),
              max_hits_subcontinent = max(hits),
              avg_pageviews_subcontinent = mean(pageviews),
              max_pageviews_subcontinent = max(pageviews))

all_data = merge(all_data, subcontinent_avg, by = 'subContinent',  all.x=TRUE)

## country
country_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(country) %>%
    summarise(
              avg_hits_country = mean(hits),
              max_hits_country = max(hits),
              avg_pageviews_country = mean(pageviews),
              max_pageviews_country = max(pageviews))

all_data = merge(all_data, country_avg, by = 'country',  all.x=TRUE)

## region
region_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(region) %>%
    summarise(
              avg_hits_region = mean(hits),
              max_hits_region = max(hits),
              avg_pageviews_region = mean(pageviews),
              max_pageviews_region = max(pageviews))

all_data = merge(all_data, region_avg, by = 'region',  all.x=TRUE)


## city
city_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(city) %>%
    summarise(
              avg_hits_city = mean(hits),
              max_hits_city = max(hits),
              avg_pageviews_city = mean(pageviews),
              max_pageviews_city = max(pageviews))

all_data = merge(all_data, city_avg, by = 'city',  all.x=TRUE)

## metro
metro_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(metro) %>%
    summarise(
              avg_hits_metro = mean(hits),
              max_hits_metro = max(hits),
              avg_pageviews_metro = mean(pageviews),
              max_pageviews_metro = max(pageviews))

all_data = merge(all_data, metro_avg, by = 'metro',  all.x=TRUE)
```


```{r web feature}
## channel grouping
channelGrouping_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(channelGrouping) %>%
    summarise(
              avg_hits_channelGrouping = mean(hits),
              max_hits_channelGrouping = max(hits),
              avg_pageviews_channelGrouping = mean(pageviews),
              max_pageviews_channelGrouping = max(pageviews))

all_data = merge(all_data, channelGrouping_avg, by = 'channelGrouping', all.x=TRUE)


## browser
browser_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(browser) %>%
    summarise(
              avg_hits_browser = mean(hits),
              max_hits_browser = max(hits),
              avg_pageviews_browser = mean(pageviews),
              max_pageviews_browser = max(pageviews))

all_data = merge(all_data, browser_avg, by = 'browser', all.x=TRUE)

## Operating system
operatingSystem_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(operatingSystem) %>%
    summarise(
              avg_hits_os = mean(hits),
              max_hits_os = max(hits),
              avg_pageviews_os = mean(pageviews),
              max_pageviews_os = max(pageviews))

all_data = merge(all_data, operatingSystem_avg, by = 'operatingSystem', all.x=TRUE)

## device group

deviceCategory_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(deviceCategory) %>%
    summarise(
              avg_hits_deviceCategory = mean(hits),
              max_hits_deviceCategory = max(hits),
              avg_pageviews_deviceCategory = mean(pageviews),
              max_pageviews_deviceCategory = max(pageviews))

all_data = merge(all_data, deviceCategory_avg, by = 'deviceCategory', all.x=TRUE)


## medium
medium_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(medium) %>%
    summarise(
              avg_hits_medium = mean(hits),
              max_hits_medium = max(hits),
              avg_pageviews_medium = mean(pageviews),
              max_pageviews_medium = max(pageviews))

all_data = merge(all_data, medium_avg, by = 'medium', all.x=TRUE)

```


```{r deviation from time}
## season
season_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(season) %>%
    summarise(
              avg_hits_season = mean(hits),
              max_hits_season = max(hits),
              avg_pageviews_season = mean(pageviews),
              max_pageviews_season = max(pageviews))

all_data = merge(all_data, season_avg, by = 'season', all.x=TRUE)


## month
month_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(month) %>%
    summarise(
              avg_hits_month = mean(hits),
              max_hits_month = max(hits),
              avg_pageviews_month = mean(pageviews),
              max_pageviews_month = max(pageviews))

all_data = merge(all_data, month_avg, by = 'month', all.x=TRUE)

## weekday
weekday_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(weekday) %>%
    summarise(
              avg_hits_weekday = mean(hits),
              max_hits_weekday = max(hits),
              avg_pageviews_weekday = mean(pageviews),
              max_pageviews_weekday = max(pageviews))

all_data = merge(all_data, weekday_avg, by = 'weekday', all.x=TRUE)

## wday
wday_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(wday) %>%
    summarise(
              avg_hits_wday = mean(hits),
              max_hits_wday = max(hits),
              avg_pageviews_wday = mean(pageviews),
              max_pageviews_wday = max(pageviews))

all_data = merge(all_data, wday_avg, by = 'wday', all.x=TRUE)

## hour
hour_avg = all_data %>%
    filter(set == 'train') %>%
    group_by(hour) %>%
    summarise(
              avg_hits_hour = mean(hits),
              max_hits_hour = max(hits),
              avg_pageviews_hour = mean(pageviews),
              max_pageviews_hour = max(pageviews))

all_data = merge(all_data, hour_avg, by = 'hour', all.x=TRUE)
```


```{r adjust column sequence}
summary(all_data)

all_data = all_data[,c(17, 18, 1:16, 19:33, 35:98, 34)]

rm(browser_avg, channelGrouping_avg, city_avg, continent_avg, country_avg, deviceCategory_avg, hour_avg, medium_avg, metro_avg, month_avg, operatingSystem_avg, region_avg, season_avg, subcontinent_avg, wday_avg, weekday_avg)
```

```{r saving point 5}
all_data$logRevenue = log(all_data$transactionRevenue + 1)

save(all_data, file = 'input/new_feature2.RData')
```


Modeling Attemp

```{r modeling}
data_train = all_data[all_data$set== 'train',-c(1,2,98)]
train_pool = catboost.load_pool(
    data = data_train[,-96],
    label = data_train[,96],
    cat_features = c(2,3,5:16,19,24,25,26,28,30,31))


data_test = all_data[all_data$set== 'test',-c(1,2,98)]
test_pool = catboost.load_pool(
    data = data_test[,-96],
    label = data_test[,96],
    cat_features = c(2,3,5:16,19,24,25,26,28,30,31))

###

fit_params <- list(loss_function = 'RMSE',
                   iterations = 4000,
                   learning_rate = 0.01,
                   random_seed = 42,
                   rsm = 0.95,
                   l2_leaf_reg = 3,
                   depth = 8,
                   one_hot_max_size = 100,
                   train_dir = 'train_dir',
                   verbose = 500)

model <- catboost.train(
    learn_pool = train_pool, 
    params = fit_params)

###

prediction <- catboost.predict(model, 
                               test_pool, 
                               prediction_type = 'RawFormulaVal')

prediction = ifelse(exp(prediction) - 1 <0, 0, exp(prediction) - 1)

submission = data.frame(
    fullVisitorId = all_data[all_data$set== 'test',]$fullVisitorId, 
    bounces = all_data[all_data$set== 'test',]$bounces,
    prediction = prediction)

submission$prediction = ifelse(submission$bounces == 1, 0, submission$prediction)

submission$bounces = NULL

submission = submission %>% 
    group_by(fullVisitorId) %>%
    summarise(PredictedLogRevenue = log(sum(prediction)+1))

submission$PredictedLogRevenue = as.character(submission$PredictedLogRevenue)

write.csv(submission, 'submission/submission092401.csv', row.names=FALSE)
# 2500, 0.05: traning RMSE: 1.6128461, LB 1.7714
# 2500, 0.01: training RMSE: 1.5893149, LB 1.7707
# 3480, 0.01: LB 1.7711
# 3480, 0.01, one_hot_max_size = 2: LB 1.7719
# 4000, 0.01, dept = 8: LB 

```

